{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: From topics to HTML. Building vizualization based on terms identified with clustering method KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 4)\n",
      "   Year  Cluster    Size                                           Features\n",
      "0  2006      0.0  6076.0  company site users video service phone time pe...\n",
      "1  2006      1.0    93.0  story story story fraud carry fraud fraud abus...\n",
      "2  2006      0.0    93.0  story story story fraud carry fraud fraud abus...\n",
      "3  2006      1.0   974.0  venture company capital partners round venture...\n",
      "4  2006      2.0  5102.0  site users video phone service people time pro...\n"
     ]
    }
   ],
   "source": [
    "# The files \"Clusters_KMeans*.csv\" are a result of applying KMeans-clustering to the origial articles. \n",
    "# Each line contains year, a cluster's number, and features (10 words that describe the cluster)\n",
    "\n",
    "df_1 = pd.read_csv(\"Clusters/Clusters_KMeans2006_2012.csv\")\n",
    "df_2 = pd.read_csv(\"Clusters/Clusters_KMeans2013.csv\")\n",
    "df_3 = pd.read_csv(\"Clusters/Clusters_KMeans2014_2017.csv\")\n",
    "\n",
    "df = df_1.append(df_2, ignore_index=True).append(df_3, ignore_index=True)\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "df['Features'] = df['Features'].str.replace(\"'\",\"\")\n",
    "df['Features'] = df['Features'].str.replace(\",\",\"\") \n",
    "df['Features'] = df['Features'].str.replace(\"[\",\"\")\n",
    "df['Features'] = df['Features'].str.replace(\"]\",\"\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.groupby(\"Year\")['Features'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "documents = df1.Features\n",
    "years = df1.Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>company site users video service phone time pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>company capital venture round ventures partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>apple iphone game time you phone re video peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>company users time google twitter people site ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>company apple google users people time faceboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011</td>\n",
       "      <td>apple google users people year time facebook s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012</td>\n",
       "      <td>game games players zynga play developers gamer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>data users google apple people companies servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>game games players playstation xbox play gamer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015</td>\n",
       "      <td>data apple users companies google service peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>game games players vr pc pokémon playstation g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>game games game dev dev pc hamze players vr ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year                                           Features\n",
       "0   2006  company site users video service phone time pe...\n",
       "1   2007  company capital venture round ventures partner...\n",
       "2   2008  apple iphone game time you phone re video peop...\n",
       "3   2009  company users time google twitter people site ...\n",
       "4   2010  company apple google users people time faceboo...\n",
       "5   2011  apple google users people year time facebook s...\n",
       "6   2012  game games players zynga play developers gamer...\n",
       "7   2013  data users google apple people companies servi...\n",
       "8   2014  game games players playstation xbox play gamer...\n",
       "9   2015  data apple users companies google service peop...\n",
       "10  2016  game games players vr pc pokémon playstation g...\n",
       "11  2017  game games game dev dev pc hamze players vr ti..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of stopwords and a list of companies' names\n",
    "#### To be excluded from a list of tchnology names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords 234\n",
      "companies' names 41\n"
     ]
    }
   ],
   "source": [
    "stopwords = ['account','autonomous','announced','ar','available','based','billion','board','build','business']\n",
    "stopwords += ['buy','buzz','calif','calls','capital','case','cell','ceo','check','china','click','companies']\n",
    "stopwords += ['comments','company','computer','conference','connected','contest','controller','couple']\n",
    "stopwords += ['credit','daily','david','deal','deals','dev','disrupt','don','drm','drug','drugs','ds','ea','email']\n",
    "stopwords += ['enterprise','event','experience','experiences','founder','files','follow','francisco','free']\n",
    "stopwords += ['funding','gamesbeat','going','got','government','growth','halo','http','inch','industry']\n",
    "stopwords += ['investors','ipo','japan','jobs','john','know','launch','life','like','links','list','little','ll']\n",
    "stopwords += ['make','lot','market','mercury','million','money','mr','need','new','news','offer','office','oil']\n",
    "stopwords += ['operating','partners','patent','patents','pay','percent','people','president','post','posted']\n",
    "stopwords += ['power','price','privacy','product','project','psp','public','quarter','raised','really']\n",
    "stopwords += ['release','results','revenue','right','round','said','sales','san','says','seattle','service']\n",
    "stopwords += ['services','silicon','site','sites','smart','software','steve','stock','store','street','students']\n",
    "stopwords += ['super','team','tech','things','think','time','tips','title','today','trump','uk','update']\n",
    "stopwords += ['user','users','valley','vehicle','vehicles','venture','ventures','version','want','way','work']\n",
    "stopwords += ['world','www','year','years','york','zuckerberg','developer','developers']\n",
    "stopwords += ['drive','driver','driving','drivers','good','technology','startup','startups']\n",
    "\n",
    "stopwords += ['是由美国资深药物开发企业家创投','fund','anything','cook','student','revenues','businesses']\n",
    "stopwords += ['someone','gillmor','investment','story','customers','square', 'gang','marks','lovehoney']\n",
    "stopwords += ['joe','keith','road','we','college','courses','education','tracks', 'day','system','stories']\n",
    "stopwords += ['hamze','zolnoski','profit','earnings','school','schools','merchants','insurance','electricity']\n",
    "stopwords += ['you','something','musk','受到实力雄厚风险投资基金','miles','wind','meters','customer', 'marketing']\n",
    "stopwords += ['fraud','publishers','allegations','titles','allegations','home','abuse','thing','labels','firm']\n",
    "stopwords += ['pp','photopress','tito','teleprompter','songs','standards','foul','re','mannes']\n",
    "\n",
    "companies = ['amazon','apple','digg','facebook','friendfeed','foursquare','google','groupon','hp','htc','myspace']\n",
    "companies += ['instagram','intel','microsoft','netflix','nexus','nintendo','nokia','nsa','oculus','palm','samsung']\n",
    "companies += ['skype','slack','snapchat','sony','spotify','sprint','techcrunch']\n",
    "companies += ['tesla','twitter','uber','venturebeat','verizon','vista','yahoo','youtube','zynga','zune','vimeo']\n",
    "companies += ['rdio']\n",
    "\n",
    "print('stopwords',len(stopwords))\n",
    "print(\"companies' names\", len(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(word):\n",
    "    if (word == 'ad') | (word == 'ads') | (word == 'advertisers'):\n",
    "        word = 'advertising'\n",
    "    elif (word == 'app') | (word == 'apps') | (word == 'applications'):\n",
    "        word = 'application'\n",
    "    elif word == 'bots':\n",
    "        word = 'bot'\n",
    "    elif word == \"cars\":\n",
    "        word = 'car'\n",
    "    elif word == 'devices':\n",
    "        word = 'device'\n",
    "    elif  word == 'intelligence':\n",
    "        word = 'ai'\n",
    "    elif (word == 'gamers') | (word == 'gaming') | (word == 'games'):\n",
    "        word = 'game'\n",
    "    elif word == 'phones':\n",
    "        word = 'phone'\n",
    "    elif (word == 'machine') | (word == 'learning'):\n",
    "        word = 'ml'\n",
    "    elif (word == 'played') | (word == 'playing'):\n",
    "        word = 'play'\n",
    "    elif (word == 'players'):\n",
    "        word = 'player'\n",
    "    elif word == 'videos':\n",
    "        word = 'video'\n",
    "    elif (word == 'virtual') | (word =='reality'):\n",
    "        word = 'vr'\n",
    "    elif word == 'chips':\n",
    "        word = 'chip'\n",
    "    elif (word == 'chatbots') | (word == 'chatbot') | (word == 'bots'):\n",
    "        word = 'bot'\n",
    "    elif word == 'headsets':\n",
    "        word = 'headset'\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three options to create three different lists for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1: To build vizualization for both technology names and companies' names\n",
    "def removeStopwords(wordlist):\n",
    "    return [w for w in wordlist if w not in stopwords]\n",
    "\n",
    "# Option 2: To build vizualization for only technology names\n",
    "def removeStopwordsANDCompanies(wordlist):\n",
    "    SWandCo = stopwords + companies\n",
    "    return [w for w in wordlist if w not in SWandCo]\n",
    "\n",
    "# Option 3: To build vizualization for only companies' names\n",
    "def Companies(wordlist):\n",
    "    return [w for w in wordlist if w in companies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the total number of words in df1 to normalize word count across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_num_words(opt):\n",
    "    \n",
    "    unique_words_total = []\n",
    "\n",
    "    for row in range(len(df1)):\n",
    "\n",
    "        year = df1.iloc[row][0]\n",
    "\n",
    "        wordlist = df1.iloc[row][1].split()\n",
    "\n",
    "        if opt == 1:\n",
    "            wordlist = removeStopwords(wordlist)\n",
    "        elif opt == 2:\n",
    "            wordlist = removeStopwordsANDCompanies(wordlist)\n",
    "        elif opt == 3:\n",
    "            wordlist = Companies(wordlist)\n",
    "        \n",
    "        unique_words_total.append(wordlist) \n",
    "    \n",
    "    unique_words_total = sum(unique_words_total,[])\n",
    "    num_words_total = len(unique_words_total)\n",
    "    unique_words_total = list(set(unique_words_total))\n",
    "    num_unique_words_total = len(list(set(unique_words_total)))\n",
    "    print(\"Total number of unique words (counted 1 time) in all clusters\",num_unique_words_total)\n",
    "    print(\"Total number of unique words (counted as many times as they are used) in all clusters\",num_words_total)\n",
    "    print(\"Unique words 2\",unique_words_total)\n",
    "    return num_words_total, sorted(unique_words_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating strings in a desired format to insert into HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function generates strings to be copied into KMeansTechInnovationsD3*.html file to build visualization\n",
    "# The foramt is  { \"Tech\":\"phone\",\"Date\":\"2005\",\"Value\":1000 }\n",
    "\n",
    "def data_for_D3(opt, num_words_total, unique_words_total):\n",
    "    df_D3_bubble = pd.DataFrame(columns = ('Year','D3_data'))\n",
    "    df_D3_bubble_ = pd.DataFrame(columns = ('Year','D3_data'))\n",
    "    \n",
    "    fieldnames = [['date']]\n",
    "    fieldnames.append(unique_words_total)\n",
    "    fieldnames = sum(fieldnames,[])\n",
    "    df_D3_line = pd.DataFrame(columns = fieldnames)\n",
    "    \n",
    "    df_D3_bubble1 = pd.DataFrame(columns = ('id','value'))\n",
    "\n",
    "    for row in range(len(df1)):\n",
    "\n",
    "        year = df1.iloc[row][0]\n",
    "        print(\"--- Year\",year) \n",
    "        \n",
    "        df_D3_bubble1.append({'id':year,'value':\"\"}, ignore_index=True)\n",
    "    \n",
    "        wordlist = df1.iloc[row][1].split()\n",
    "        \n",
    "        if opt == 1:\n",
    "            wordlist = removeStopwords(wordlist)         \n",
    "        elif opt == 2:\n",
    "            wordlist = removeStopwordsANDCompanies(wordlist)\n",
    "        elif opt == 3:\n",
    "            wordlist = Companies(wordlist)\n",
    "        \n",
    "        wordfreq = []\n",
    "        for w in wordlist:\n",
    "            wordfreq.append(wordlist.count(w))\n",
    "\n",
    "        l = sorted(list(zip(wordlist, wordfreq)), key=lambda x: x[1], reverse = True)\n",
    "        ll = list(set(l))\n",
    "        lll = sorted(ll, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        \"\"\"\n",
    "        I need the following format to insert into KMeansTechInnovationsD3*.html file \n",
    "        { \"Tech\":\"phone\",\"Date\":\"2005\",\"Value\":1000 },\n",
    "        \n",
    "        \"\"\"    \n",
    "    \n",
    "        top_words = 30\n",
    "        for i in lll[:top_words]:\n",
    "            normalized_word_count = i[1]/num_words_total\n",
    "            D3_word = lemmatization(i[0])\n",
    "            lll_D3 = '{ \"Tech\":' + '\"' + D3_word + '\"' + ',\"Date\":' + '\"' + str(year) + '\"' + ',\"Value\":'+ str(normalized_word_count) + ' },'\n",
    "            # multiplying 'normalized_word_count' by 10,000 for the value to be seen in visualization\n",
    "            lll_D3_ = '{ \"Tech\":' + '\"' + D3_word + '\"' + ',\"Date\":' + '\"' + str(year) + '\"' + ',\"Value\":'+ str(normalized_word_count*10000) + ' },'\n",
    "            df_D3_bubble = df_D3_bubble.append({'Year':year,'D3_data':lll_D3}, ignore_index=True)\n",
    "            df_D3_bubble_ = df_D3_bubble_.append({'Year':year,'D3_data':lll_D3_}, ignore_index=True)\n",
    "            \n",
    "            df_D3_line_date = str(year)+'0101'\n",
    "            df_D3_line = df_D3_line.append({'date':df_D3_line_date, D3_word:i[1]}, ignore_index=True)\n",
    "            \n",
    "            id_D3 = str(year) + \".\" + D3_word\n",
    "            df_D3_bubble1 = df_D3_bubble1.append({'id':id_D3,'value':i[1]}, ignore_index=True)\n",
    "               \n",
    "    df_D3_line_noNA = df_D3_line.fillna(0)\n",
    "    print(\"df_D3_line_noNA\",df_D3_line_noNA.shape)\n",
    "    \n",
    "    df_D3_bubble1 = df_D3_bubble1.groupby('id')['value'].sum().reset_index()\n",
    "    \n",
    "    df_D3_bubble.to_csv(\"Viz/KMeansTechInnovationsD3_opt\"+str(opt)+\".csv\")\n",
    "    df_D3_bubble_.to_csv(\"Viz/KMeansTechInnovationsD3_opt\"+str(opt)+\"_.csv\")\n",
    "    df_D3_line_noNA.to_csv(\"Viz/KMeansTechInnovationsD3_line_opt\"+str(opt)+\".csv\", index = False)\n",
    "    df_D3_bubble1.to_csv(\"Viz/KMeansTechInnovationsD3_bub1_opt\"+str(opt)+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating files with terms and their relative amount of mentioning in tech news to build visualizations\n",
    "#### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Year 2006 lenght of the word set 74\n",
      "--- Year 2007 lenght of the word set 81\n",
      "--- Year 2008 lenght of the word set 80\n",
      "--- Year 2009 lenght of the word set 80\n",
      "--- Year 2010 lenght of the word set 78\n",
      "--- Year 2011 lenght of the word set 66\n",
      "--- Year 2012 lenght of the word set 70\n",
      "--- Year 2013 lenght of the word set 71\n",
      "--- Year 2014 lenght of the word set 66\n",
      "--- Year 2015 lenght of the word set 65\n",
      "--- Year 2016 lenght of the word set 82\n",
      "--- Year 2017 lenght of the word set 78\n",
      "Total number of words (unique features) in all clusters 891\n",
      "--- Year 2006\n",
      "--- Year 2007\n",
      "--- Year 2008\n",
      "--- Year 2009\n",
      "--- Year 2010\n",
      "--- Year 2011\n",
      "--- Year 2012\n",
      "--- Year 2013\n",
      "--- Year 2014\n",
      "--- Year 2015\n",
      "--- Year 2016\n",
      "--- Year 2017\n"
     ]
    }
   ],
   "source": [
    "# Option 1: use all words that are present in clusters from Clusters_KMeans*.csv \n",
    "# including names of both technologies and companies\n",
    "num_words_total = total_num_words(1)\n",
    "data_for_D3(1,num_words_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words (counted 1 time) in all clusters 181\n",
      "Total number of unique words (counted as many times as they are used) in all clusters 2943\n",
      "Unique words 2 ['jpg', 'mac', 'intelligence', 'friends', 'advertisers', 'media', 'com', 'model', 'alexa', 'games', 'tweets', 'emissions', 'fusion', 'ray', 'panels', 'video', 'action', 'radio', 'gowalla', 'card', 'android', 'ipod', 'discs', 'patients', 'assistant', 'play', 'photos', 'moogaloop', 'blog', 'shares', 'byline', 'location', 'recording', 'information', 'feature', 'id', 'headsets', 'health', 'energy', 'healthcare', 'photo', 'consoles', 'chatbot', 'use', 'mobilecrunch', 'game', 'chip', 'utilities', 'doctors', 'accounts', 'grooveshark', 'thumb', 'payment', 'reader', 'ipad', 'marketers', 'playstation', 'share', 'security', 'car', 'chips', 'network', 'image', 'hd', 'wallet', 'pokémon', 'tools', 'app', 'carry', 'application', 'beats', 'cars', 'channel', 'galaxy', 'voice', 'lumia', 'itunes', 'iphone', 'ads', 'advertising', 'sciences', 'care', 'apps', 'preview', 'battery', 'teachers', 'marketplace', 'dvd', 'teare', 'smartphone', 'blackberry', 'content', 'song', 'tablets', 'artists', 'macbook', 'briefing', 'analytics', 'bitcoin', 'machine', 'snap', 'nano', 'partnerup', 'server', 'tablet', 'reality', 'bots', 'wireless', 'call', 'music', 'web', 'bd', 'self', 'cortana', 'feed', 'patient', 'stay', 'pixel', 'ai', 'console', 'cards', 'vr', 'bot', 'series', 'session', 'wii', 'pc', 'maps', 'chatbots', 'phone', 'color', 'xbox', 'headset', 'hulu', 'windows', 'ad', 'platform', 'camera', 'cable', 'phones', 'currency', 'mobile', 'messages', 'cloud', 'messenger', 'page', 'dock', 'rift', 'mini', 'program', 'gamers', 'blip', 'gmail', 'places', 'engine', 'show', 'payments', 'glass', 'watch', 'device', 'swf', 'blu', 'tweet', 'player', 'surface', 'gox', 'tv', 'data', 'applications', 'box', 'carbon', 'search', 'portrait', 'zunes', 'players', 'chrome', 'clip', 'videos', 'devices', 'grid', 'ios']\n",
      "--- Year 2006\n",
      "--- Year 2007\n",
      "--- Year 2008\n",
      "--- Year 2009\n",
      "--- Year 2010\n",
      "--- Year 2011\n",
      "--- Year 2012\n",
      "--- Year 2013\n",
      "--- Year 2014\n",
      "--- Year 2015\n",
      "--- Year 2016\n",
      "--- Year 2017\n",
      "df_D3_line_noNA (360, 183)\n"
     ]
    }
   ],
   "source": [
    "# Option 2: remove stopwords and companies' names \n",
    "num_words_total,unique_words_total = total_num_words(2)\n",
    "data_for_D3(2,num_words_total,unique_words_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words (counted 1 time) in all clusters 38\n",
      "Total number of unique words (counted as many times as they are used) in all clusters 1231\n",
      "Unique words 2 ['yahoo', 'zune', 'venturebeat', 'sprint', 'techcrunch', 'vista', 'intel', 'samsung', 'nintendo', 'google', 'groupon', 'nsa', 'microsoft', 'friendfeed', 'hp', 'apple', 'facebook', 'myspace', 'snapchat', 'youtube', 'slack', 'oculus', 'tesla', 'zynga', 'spotify', 'foursquare', 'instagram', 'palm', 'netflix', 'nexus', 'htc', 'amazon', 'twitter', 'skype', 'verizon', 'uber', 'sony', 'nokia']\n",
      "--- Year 2006\n",
      "--- Year 2007\n",
      "--- Year 2008\n",
      "--- Year 2009\n",
      "--- Year 2010\n",
      "--- Year 2011\n",
      "--- Year 2012\n",
      "--- Year 2013\n",
      "--- Year 2014\n",
      "--- Year 2015\n",
      "--- Year 2016\n",
      "--- Year 2017\n",
      "df_D3_line_noNA (163, 39)\n"
     ]
    }
   ],
   "source": [
    "# Option 3: keep only compnaies' names to build vosualization for compnaies evolution \n",
    "num_words_total,unique_words_total = total_num_words(3)\n",
    "data_for_D3(3,num_words_total,unique_words_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
